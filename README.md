# Paper_Survey

# Computer Vision
|Year|Journal/Conference|Title|Reviewer|Links|
|:-:|:-:|:-|:-:|:-:|
|2023|arXiv|ControlNet : Adding Conditional Control to Text-to-Image Diffusion Models|김현일|[Paper](https://arxiv.org/pdf/2302.05543.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/21), [PPT](https://docs.google.com/presentation/d/167RWT8uAwJ5WS4FAbq_RKu5uNED_Jfoi/edit?usp=share_link&ouid=113313327863072169561&rtpof=true&sd=true)
|2022|CVPR|ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-high Resolution Segmentation|김현일|[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/22), [Code](https://github.com/cedricgsh/ISDNet), [PPT](https://docs.google.com/presentation/d/10N-WiyaoXbXoV8kLluBXJ-oHrSJM-_Ev/edit?usp=share_link&ouid=113313327863072169561&rtpof=true&sd=true)
|2022|arXiv|Instant Neural Graphics Primitives with a Multiresolution Hash Encoding  |김현일|[Paper](https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/16), [ppt](https://docs.google.com/presentation/d/1uvvDOp65Guo9dxTVXsJa5Z2b4R9MuuGgcaYKUmePTNg/edit?usp=sharing)|
|2022|arXiv|EfficientFormer : Vision Transformers at MobileNet Speed |김현일|[Paper](https://arxiv.org/abs/2206.01191.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/17), [ppt](https://docs.google.com/presentation/d/1mByIQVSCxaHjZJf4jx3nG6ddM4j_RY5LZF6TGsXB-Os/edit#slide=id.g1315fd7a39e_0_6)|
|2020|ECCV|NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis |김현일|[Paper](https://arxiv.org/abs/2003.08934.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/18), [ppt](https://docs.google.com/presentation/d/1pnuG4VCcBdKybVN-ULSo3n0qKV6rbpKFiJ1C9L_d30M/edit?usp=sharing)|
|2021|arXiv|Masked-attention Mask Transformer for Universal Image Segmentation |김현일|[Paper](https://arxiv.org/pdf/2112.01527.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/10)|
|2021|nips|Per-Pixel Classification is Not All You Need for Semantic Segmentation |김현일|[Paper](https://arxiv.org/pdf/2107.06278.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/9)|
|2021|arXiv|A Survey of Visual Transformers |김현일|[Paper](https://arxiv.org/pdf/2111.06091.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/8), [ppt](https://github.com/gusdlf93/Paper_Survey/files/7887540/Vision.Transformers.pptx)|
|2021|CVPR|Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers |김현일|[Paper](https://arxiv.org/abs/2012.15840), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/5)|
|2021|ICCV (Spotlight)|LAMBDANETWORKS: MODELING LONG-RANGE INTERACTIONS WITHOUT ATTENTION|김현일|[Paper](https://openreview.net/pdf?id=xTJEN-ggl1b), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/3)|
|2021|arXiv|MOBILEVIT: LIGHT-WEIGHT, GENERAL-PURPOSE, AND MOBILE-FRIENDLY VISION TRANSFORMER|김현일|[Paper](https://arxiv.org/abs/2110.02178), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/2)|
|2021|arXiv|ResNet strikes back: An improved training procedure in timm|김현일|[Paper](https://arxiv.org/abs/2110.00476), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/1)|
|2022|arXiv|Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time|김현일|[Paper](https://arxiv.org/abs/2203.05482), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/20), [PPT](https://docs.google.com/presentation/d/1Vy1U_Di_461xAVrZuzQxdwRLxIqjpVzBLjSyey__TEM/edit?usp=sharing)

# Knowledge Distillation
|Year|Journal/Conference|Title|Reviewer|Links|
|:-:|:-:|:-|:-:|:-:|
2021|NIPS|Does Knowledge Distillation Really Work? |김현일|[Paper](https://papers.nips.cc/paper/2021/file/376c6b9ff3bedbbea56751a84fffc10c-Paper.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/14), [ppt](https://github.com/gusdlf93/Paper_Survey/files/8791484/Knowledge.Distillation.pdf)|
|2021|arXiv|Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results |김현일|[Paper](https://arxiv.org/pdf/2204.03475.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/15), [ppt](https://github.com/gusdlf93/Paper_Survey/files/8791484/Knowledge.Distillation.pdf)|
|2021|IJCV| Knowledge Distillation: A Survey |김현일|[Paper](https://arxiv.org/pdf/2006.05525.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/13), [ppt](https://github.com/gusdlf93/Paper_Survey/files/8791484/Knowledge.Distillation.pdf)|

# Loss Function
|Year|Journal/Conference|Title|Reviewer|Links|
|:-:|:-:|:-|:-:|:-:|
|2019|CVPR|ArcFace: Additive Angular Margin Loss for Deep Face Recognition |김현일|[Paper](https://arxiv.org/pdf/1801.07698.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/7)|

# Self-Supervised Learning
|Year|Journal/Conference|Title|Reviewer|Links|
|:-:|:-:|:-|:-:|:-:|
|2022|arxiv|Hydra Attention: Efficient Attention with Many Heads|김현일|[Paper](https://arxiv.org/pdf/2209.07484.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/19)
|2021|arxiv|Masked Autoencoders Are Scalable Vision Learners|김현일|[Paper](https://arxiv.org/pdf/2111.06377.pdf), [Summary](https://github.com/gusdlf93/Paper_Survey/issues/6), [ppt](https://github.com/gusdlf93/Paper_Survey/files/7658356/Masked.autoencoders.are.scalable.vision.learners.pptx)|

# Medical
|Year|Journal/Conference|Title|Reviewer|Links|
|:-:|:-:|:-|:-:|:-:|
|2022|Deep Bio ppt| Stain Normalization Survey |김현일|[Summary](https://github.com/gusdlf93/Paper_Survey/issues/12),[ppt](https://docs.google.com/presentation/d/1SR5xTKa0x5CpZckJayaA_BmRpTAqdvp6svjj7_zsQFc/edit?usp=sharing)|
